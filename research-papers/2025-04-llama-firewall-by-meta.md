# 2025-04 LlamaFirewall: An open source guardrail system for building secure AI agents by Meta

> Retrieved on 2025-09-06 by @KemingHe from [[ai.meta.com](https://ai.meta.com/research/publications/llamafirewall-an-open-source-guardrail-system-for-building-secure-ai-agents/)]

## Files

- **PDF**: [[Original Document](https://drive.google.com/file/d/1CCQBVkHjEfdAFP2cr-I7MeLqfJsvj-yZ/view?usp=sharing)]
- **Audio**: [[Audio Overview](https://drive.google.com/file/d/1prByVZW84CyuLb73G3Qq-g1dAimH25cj/view?usp=sharing)]
- **Video**: [[Video Overview](https://drive.google.com/file/d/19NZcS6LOraONo41FfvSmvrZijHwwY4Xz/view?usp=sharing)]

## Significance

Meta's production-tested framework introduces 3 guardrails achieving over 90% attack success rate reduction: PromptGuard 2's universal jailbreak detection, AlignmentCheck's chain-of-thought auditing, and CodeShield covering 50+ vulnerability patterns across 8 programming languages.

As AI agents evolve beyond chatbots to perform high-stakes tasks like editing production code, traditional security measures prove inadequate against emerging application-layer threats including prompt injection, goal hijacking, and insecure code generation.

This open-source framework empowers AI security engineers, cybersecurity professionals, and system architects to build real-time defense systems against the evolving threat landscape of autonomous AI agents.

---

> Cybersecurity and AI Governance Summary Template v1.0.0 - KemingHe/cybersecurity-and-ai-governance-readings
