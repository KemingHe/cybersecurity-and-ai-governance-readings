# Security Controls and LLM Firewalls

> **Retrieved on**: 2026-01-07 by Keming He from [Securiti - AI Security & Governance Certification - Module 7 - Security Controls and LLM Firewalls](https://education.securiti.ai/certifications/ai-governance/controlling-data-inputs-and-outputs/security-controls-and-llm-firewalls/)

## Overview

To enhance the security of AI interactions, the implementation of [LLM (Large Language Models) firewalls](https://securiti.ai/what-is-llm-firewall/) has become crucial. These firewalls serve as sophisticated security measures, designed to filter out harmful prompts, data retrievals, and responses. They act as a protective barrier for AI systems, safeguarding against external attacks, malicious internal use, and misconfigurations. LLM firewalls should have built-in policies that cover sensitive data, tone, topic, phishing, and attacks, ensuring comprehensive security and compliance. Additionally, they should allow for the creation of new policies and implement actions such as redaction, message blocking, and session termination, all built on a proven policy framework. Let us delve into the specifics of different types of LLM firewalls, each catering to a unique aspect of AI security.

## Types of LLM Firewalls

### Prompt Firewall

The Prompt Firewall scrutinizes user prompts directed at an LLM, along with any associated data, to preemptively identify and mitigate potential malicious use:

- **Sensitive Information**: By redacting sensitive information from prompts, it prevents the LLM from searching for or retrieving protected data, thereby enhancing privacy and security.
- **Phishing Prevention**: It blocks attempts to retrieve personal, authentication, or financial information, thereby thwarting phishing efforts directly at the prompt level.
- **Jailbreak / Prompt Injection**: This feature actively prevents attempts to circumvent the LLM's built-in protections through common jailbreaking or prompt injection tactics.
- **Additional Protections**: It also addresses anomalies in access patterns, knowledge scraping, toxic behavior, engagement with prohibited topics, and unauthorized source code submission.

### Retrieval Firewall

The Retrieval Firewall is specifically engineered to monitor and control the data retrieved during Retrieval Augmented Generation (RAG) processes. This type of firewall plays a critical role in several areas:

- **Sensitive Information**: It redacts any sensitive data encountered during the retrieval process and logs the event for further investigation, ensuring that personal or confidential information is not inadvertently exposed.
- **Topic Compliance**: It ensures that the data retrieved is relevant and adheres to the specified topic criteria, aligning with the chatbot's intended use or the conversation's context.
- **Indirect Prompt Injection**: It examines retrieved data for attempts at data poisoning or efforts to compromise the LLM through prompt injections or jailbreaking techniques.

### Response Firewall

The Response Firewall is tasked with examining and regulating the responses generated by LLMs to ensure they align with user expectations and maintain a high standard of security:

- **Sensitive Information**: Any sensitive information produced in the model’s response is immediately redacted, protecting users from unintended data exposure.
- **Toxicity and Sentiment Control**: Responses containing toxic content or negative sentiment are blocked, fostering a positive and respectful interaction environment.
- **Content Filtering**: Beyond the immediate concerns, it also filters out responses that may be irrelevant, engage with prohibited topics, or contain unauthorized source code.
- **Streaming Operation**: It analyzes the responses in real-time, ensuring that they are not only prompt but also accurately reflect the user’s query or command.

## Summary

Through these specialized firewalls, AI systems are equipped with robust mechanisms to preemptively identify and neutralize potential security threats, ensuring that interactions remain secure, relevant, and aligned with ethical standards and regulatory requirements. Ultimately, the goal is not to limit AI progress but to channel it wisely. LLM firewalls help strike that balance. They enable cutting-edge systems that enrich our lives while restricting harmful or biased content that should not be amplified.
